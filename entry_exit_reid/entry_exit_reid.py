"""
Description:
    Class: Entry_Exit_REID
    This class is used for entry exit reid implementation.
    The implementation combains yolov7 (detector), bytetrack
    (tracker), and OsNet reid model to solve the problem.
    This class will manage each track ids when a person enter 
    or exit a entry-exit area
author:
    muhammad nur ilmi-Gadjah Mada University, Yogyakarta, Indonesia
    mnurilmi18@gmail.com
"""
import numpy as np
import time
import cv2
import os
import csv

from tracker.basetrack import TrackState

import torch
from scipy.spatial import distance

class TrackState_(TrackState):
    # EER state adaptation from ByteTrack
    In = 4
    Matching = 5

class Entry_Exit_REID(object):
    def __init__(
        self,
        entry_area_config,        
        feat_extractor,
        feat_match_thresh,
        match_count_thresh = 3,
        save_patch_dir = None
        ):
        self.frame_id = 0
        self.last_id = 0

        self.db = {}
        self.output = []
        self.system_recorder = {
            "total_person_in_frame": [],
            "total_ID_tobe_matched_by_query": [],
            "saving_db":0,
            "matching_db":0,
            "match":0,
            "frame_indices":[]
        }
        self.EER_recorder = []
        self.contours = self.get_contours(entry_area_config)
        
        torch.backends.cudnn.enabled = True 
        print("CUDA is active?: ", torch.cuda.is_available())
        print("cudnn enable?", torch.backends.cudnn.is_available())
        
        # Reid model inisialization        
        self.feat_extractor = feat_extractor
        self.feat_match_thresh = feat_match_thresh 
        self.match_count_threshold = match_count_thresh
        
        if save_patch_dir != None:
            self.save_patch_dir = save_patch_dir
            os.mkdir(str(save_patch_dir)+"/sample_patch")
            
        print("Feature matching treshold:", self.feat_match_thresh)
        print("===Entry Exit REID ready!===")

    def get_contours(self, config):
        """Get contours parameter from config area file

        Args:
            config (Dict): Dictionary of json config file

        Returns:
            contours (list): list tuple of the entry area contours
        """
        self.img_h = config["img_h"]
        self.img_w = config["img_w"]
        src = np.zeros((config["img_h"], config["img_w"]), dtype=np.uint8) 
        cv2.line(src, tuple(config["points"][0]), tuple(config["points"][1]),(255,0,0), 3)
        cv2.line(src, tuple(config["points"][1]), tuple(config["points"][2]),(255,0,0), 3)
        cv2.line(src, tuple(config["points"][2]), tuple(config["points"][3]),(255,0,0), 3)
        cv2.line(src, tuple(config["points"][3]), tuple(config["points"][0]),(255,0,0), 3)
        contours, _ = cv2.findContours(src, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        # print(contours)
        # cv2.imwrite(f"a.jpg", src)
        return contours

    def next_id(self):
        """Generate new ID
        On this project, ID is a integer and will generated increamentally

        Returns:
            last_id (int): last id generated by system
        """
        self.last_id += 1
        return self.last_id
       
    def update(self, ot, im0):
        """
        Steps:
        - bbox centroid calculation and feature extraction
        - Entry Area configuration to determine a centroid in entry area or not
        - Assigning ID based on state each tracks
        """
        self.frame_id += 1
        self.system_recorder["total_person_in_frame"].append(len(ot))
        if len(ot) == 0:
            # continue to next frame if no tracks detected
            return []
        
        im1 = im0.copy()
        centroids, patches = self.get_centroids_and_patches(ot, im1)    # matrix operation and iteration process
        feats = self.extract_feature(patches)                           # One inference process (many objects)
        self.set_ids(ot, feats, patches, centroids)                  # iteration process
        return ot

    def get_centroids_and_patches(self, ot, im1):
        """Generating Centroids and Patches

        Args:
            ot (object): online tracks from tracker
            im1 (numpy array): current frame image

        Returns:
            centroids, patches: list of centroids, list of patches
        """
        tlbrs = [ot[i].tlbr for i in range(len(ot))]
        patches = [self.extract_patch(im1, ot[i].tlbr) for i in range(len(ot))]

        tlbrs_np = np.array(tlbrs)
        
        # bottom centroid
        Mx = np.array([[1/2],[0],[1/2],[0]]) # left, right
        My = np.array([[0],[0],[0],[1]])     # top, bottom

        # # Middle centroid (center of bbox)
        # Mx = np.array([[1/2],[0],[1/2],[0]]) # left, right
        # My = np.array([[0],[0],[0],[1]])     # top, bottom

        Cx = np.dot(tlbrs_np, Mx).astype(int).flatten()
        Cy = np.dot(tlbrs_np, My).astype(int).flatten()
        
        centroids = np.transpose(np.array([Cx, Cy]))
        return centroids, patches

    def save_patch(self, fname, patch):
        cv2.imwrite(f"{fname}.jpg", patch)
        
    def extract_patch(self, img, tlbr, target_size = (128, 256)):
        tlbr = np.array(tlbr).astype(int)
        tlbr[0] = (max(0, tlbr[0]))
        tlbr[1] = (max(0, tlbr[1]))
        tlbr[2] = (min(img.shape[1] - 1, tlbr[2])) # relative to W
        tlbr[3] = (min(img.shape[0] - 1, tlbr[3])) # relative to H

        patch = img[
            tlbr[1]:tlbr[3],
            tlbr[0]:tlbr[2]
        ]
        cv2.resize(patch, target_size)
        return patch

    def extract_feature(self, patches):
        """Feature extraction of all online track bounding boxes
            The REID model will do inferencing to all patches and return features of every patch
        Args:
            patches (list): list of person patches
        """
        features = self.feat_extractor(patches)
        if torch.cuda.is_available():
                torch.cuda.synchronize()
        return features.cpu().data.numpy()
        
    def update_track(self, ot, index, feats_np, centroids, bias = 30):   
        """Track update

        Args:
            index (int): index of each online tracks
            ot (object): online tracks from tracker
            feats_np (numpy array): feature of each tracks
            centroids (list): list of centroid tuple (x, y) in the image
            bias (int, optional): centroid bias if it beyond the image (automatically adjusted to the image). Defaults to 30.
        """
        if centroids[index][0] > self.img_w - bias:
            centroids[index][0] = self.img_w -bias
        if centroids[index][1] > self.img_h - bias:
            centroids[index][1] = self.img_h - bias
            
        ot[index].set_centroid((centroids[index][0],centroids[index][1]))
        ot[index].update_feat(feats_np[index])
        # print(type(ot[index].get_feat()))

    def set_ids(self, ot, feats_np, patches, centroids):
        """Set IDs (ID Assigner)

        Args:
            - ot (list of object): list of online tracks
            - feats_np (numpy array): features from previous reid model inference process
            - centroids (list): centroid position of each online tracks
        
        Tasks:
            - update online track attributes
            - set each online track id's
        """
        # print("===set ids===   ", len(ot), "tracks online")
        for i in range(len(ot)):
            # update current track attribute
            self.update_track(ot, i, feats_np, centroids)
            # procedure for assigning ID of each tracks
            self.id_assigner_procedure(ot, i, patches)
            
        # print("data in database: ", self.db.keys())

    def id_assigner_procedure(self, ot, i, patches):
        """
        Args:
            - ot (list of object): list of online tracks
            - i (int): index of ot  
        algorithm notes:
            * default state: Tracked
            * features are saved just once when the track pass the line for the first time
            * Impossible condition are:
                * id -1; any state except tracked

        """
        print(i, "-", end = " ")
        t_last_id = ot[i].get_id()                          # track last ID
        t_last_state = ot[i].get_last_state()               # track last state
        is_in_entry_area = self.is_in_entry_area(ot[i].get_centroid())    # whether track passed the entry area or not
        # feat = ot[i].get_feat()[-1]                         # current track feature to be saved or matched depends on state
        
        if t_last_id == -1:
            if not is_in_entry_area:
                # set new id, last state unchanged (tracked)
                ot[i].set_id(self.next_id())
            else:
                ot[i].set_last_state(TrackState_.Matching)
                # matching db for the first time
                ot[i] = self.matching_db(ot[i])
        else:
            if not is_in_entry_area:
                if t_last_state == TrackState_.Matching:
                    # Exit event condition, transition Matching to Tracked; save result
                    # Final ID will be determined
                    
                    val_id, count = ot[i].get_max_match_count()
                    print("Valid ID:", val_id)
                    if val_id != None and count >= self.match_count_threshold:
                        ot[i].set_id(val_id)
                    else:
                        ot[i].set_id(ot[i].get_temp_id())
                        
                    self.output.append(ot[i].get_id())
                    self.set_EER_recorder(ot[i].get_id(), "Exit", self.get_local_time())
                    if self.save_patch_dir != None:
                        self.save_patch(f"{self.save_patch_dir}/sample_patch/{ot[i].get_id()} exit",patches[i])
                # tracking as usual until cross/pass the entry area
                ot[i].set_last_state(TrackState_.Tracked)
                
            else:
                if  t_last_state == TrackState_.Tracked:
                    # Enter event condition, transition Tracked to In, save track features to DB
                    self.save_2_db(ot[i])
                    
                    ot[i].set_last_state(TrackState_.In)
                    if self.save_patch_dir != None:
                        self.save_patch(f"{self.save_patch_dir}/sample_patch/{t_last_id} in",patches[i])
                        
                elif t_last_state == TrackState_.Matching:
                    # matching db until the track leaves the entry area
                    ot[i] = self.matching_db(ot[i])
                    
                else:
                    # tracking as usual
                    pass
                
        # print(ot[i].get_id())
        # print(ot[i].get_max_match_count())  
        print(ot[i].get_match_count(), end = " ")   
                    
    def is_in_entry_area(self, centroid):
        if cv2.pointPolygonTest(self.contours[0], (int(centroid[0]), int(centroid[1])), True) < 0:
            # if negative it means the centroid is on the outside of entry area
            return False
        else:
            return True

    def matching_db(self, ot_):
        """Matching DB and set the current track ID
            When current track feature match with feature on the gallery,
            the matched ID will be save to "val_id and match_count" dictionary. 
            So, it can be used to determine final ID after a person on exit condition
        Args:
            feat_ (numpy array): feature of current track
            ot (object): current track
        """
        self.log_event("matching_db")
        # ids = list(self.db.keys())
        # print("data in database: ", ids)  
        ot = ot_
        # match_count = ot.get_match_count()
        val_id_idx = ot.get_val_id_idx()
        match_id = self.is_query_match_gallery(ot.get_feat()[-1], val_id_idx)
        if match_id != None:
            ot.set_id(match_id)
            ot.set_match_count(match_id)            # increase the val_ids index and match_count
            ot.set_val_id_idx()
        else:
            if ot.get_temp_id() == None:
                # print("next ID!!!!!!!!!!!!!!!!!!!!!")
                ot.set_id(self.next_id())
                ot.set_temp_id(ot.get_id())
            else:
                ot.set_id(ot.get_temp_id())
        
        return ot # return updated current track
        
        
        # match_id_idxs = ot.get_match_id_idxs()
        
        # if not bool(match_count):
        #     # if val_ids still empty, gallery index will start from index 0
        #     ot, match_id = self.is_query_match_gallery(ot.get_feat()[-1], None, 0, ot)
            
        #     if match_id != None:
        #         ot.set_id(match_id)
        #         ot.set_match_count(match_id)            # increase the val_ids index and match_count
        #         ot.set_match_id_idxs(match_id)
        #     else:
        #         if ot.get_temp_id() == None:
        #             # print("next ID!!!!!!!!!!!!!!!!!!!!!")
        #             ot.set_id(self.next_id())
        #             ot.set_temp_id(ot.get_id())
        #         else:
        #             ot.set_id(ot.get_temp_id())
        # else:
        #     match_ids = []
        #     for key, _ in match_count.items(): 
        #         ot, match_id = self.is_query_match_gallery(ot.get_feat()[-1], key, match_id_idxs[key], ot)
        #         ot.set_match_id_idxs(key)
        #         match_ids.append(match_id)
                
        #     for match_id in match_ids:
        #         if match_id != None:
        #             ot.set_id(match_id)                     # set current track id
        #             ot.set_match_count(match_id)            # increase the val_ids index and match_count
        #         else:
        #             if ot.get_temp_id() == None:
        #                 # print("next ID!!!!!!!!!!!!!!!!!!!!!")
        #                 ot.set_id(self.next_id())
        #                 ot.set_temp_id(ot.get_id())
        #             else:
        #                 ot.set_id(ot.get_temp_id())


            
            
    def is_query_match_gallery(self, feat_, match_id_idx, metric = "cosine"):
        """Matching one query to many gallery at certain index

        Args:
            feat_ (numpy array): current track feature
            val_idx (int): feature_history index on gallery feature
            ot (object): current track that being evaluated
            metric (str, optional): matching similarity type. Defaults to "cosine".

        Returns:
            _type_: _description_
        """
        gallery = []
        gallery_ids = []
        gallery_index = match_id_idx
        print("v:", match_id_idx)
        for id_ in self.db.keys():
            # collect feature from the gallery at some index based on feature history
            feats = self.db[id_]["registered_object"].get_feat()
            # if  gallery_index >= len(feats) and val_id != None:
            #     ot.reset_val_ids(val_id)
            #     gallery_index = 0
            if gallery_index < len(feats):
                gallery_ids.append(id_)
                gallery.append(np.array(feats[gallery_index]))
                
        if len(gallery_ids) == 0:
            return None    

        self.system_recorder["total_ID_tobe_matched_by_query"].append(len(gallery_ids))  
            
        query = np.array(feat_[np.newaxis,:])
        gallery = np.array(gallery)

        # Similarity calculation (default cosine)
        ds = distance.cdist(
                    query,
                    gallery, 
                    metric
                )[-1]
        ds = ds.tolist()
        match_id = gallery_ids[self.argmin(ds)] # get the gallery ID that most similar to the query
        min_score = min(ds)
        
        print("\tSCORE: ", ds)
        print(min_score, "-", gallery_ids[self.argmin(ds)])

        if  min_score <= self.feat_match_thresh:
            # A query match to the gallery if the minimum score below or equals to feat_match_thresh
            self.log_event("match")
            self.system_recorder["frame_indices"].append(self.frame_id)
            
            return match_id
        else:
            return None

    def save_2_db(self, t):
        # saving feature to db
        # print(t.get_id(), " SAVE FITUR 2 DB!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
        self.log_event("saving_db")
        self.db[t.get_id()] = {
            "registered_object": t
        }
        self.set_EER_recorder(t.get_id(), "Enter", self.get_local_time())
    
    def argmin(self, lst):
      return lst.index(min(lst))
    
    def argmax(self, lst):
      return lst.index(max(lst))
  
    def get_local_time(self):
      # get local time in UTC format
      return time.asctime(time.gmtime())

    def get_total_person(self):
        if len(self.system_recorder["total_person_in_frame"]) == 0:
            return 0
        else:
            return self.system_recorder["total_person_in_frame"][-1] # get last frame total person
    
    def set_EER_recorder(self, id, event, UTC_time):
        self.EER_recorder.append(
            {   
                'id': id,
                'event': event,
                'UTC_time': UTC_time
            }
        )
        
    def get_EER_recorder(self):
        return self.EER_recorder
    
    def generate_EER_recorder_csv(self, fname):
        fname = fname+".csv"
        with open(fname, 'w') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames = ['id', 'event', 'UTC_time'])
            writer.writeheader()
            writer.writerows(self.get_EER_recorder())
        print("=====EER recorder generated=====")
    
    def log_event(self, event):
        if event not in self.system_recorder.keys():
            self.system_recorder[event] = 1
        else:    
            self.system_recorder[event] += 1

    def log_report(self):
        print("\n=====REPORT EVENT=====")
        print(self.system_recorder)
    
    def sample_db(self):
        print("\n===== SAMPLE DATABASE=====")
        print(self.db)
        for key in self.db.keys():
            feats = self.db[key]["registered_object"].get_feat()
            print("saved feature history length: ", len(feats))
            print("each feature shape: ", feats[0].shape)
            # print(feats[0])
            # print(feats[1])
            # print(distance.cdist(
            #         feats[0][np.newaxis,:],
            #         feats[0][np.newaxis,:],
            #         "cosine"))
            # print(distance.cdist(
            #         feats[0][np.newaxis,:],
            #         feats[5][np.newaxis,:],
            #         "cosine"))
    
    def log_output(self):
        print(f"ID to evaluate (Exit condition):{len(self.output)}\n", self.output)
        print(self.get_EER_recorder())
        max_total_person = max(self.system_recorder["total_person_in_frame"])
        max_gallery_ID = max(self.system_recorder["total_ID_tobe_matched_by_query"])
        print(f"\nmax person in frame: {max_total_person} ")
        print(f"\nmax total gallery IDS to be matched: {max_gallery_ID} ")